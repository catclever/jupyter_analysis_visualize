# Jupyter Analysis Visualize

A data analysis visualization platform for exploring Jupyter notebook-based analysis projects. Display project DAGs (Directed Acyclic Graphs), view node dependencies, and inspect execution results with Parquet-based result storage.

## Features

- **Project Management**: Load and switch between multiple analysis projects
- **Flow Visualization**: Interactive DAG visualization with dependency tracking
- **Result Inspection**: View and paginate through execution results (Parquet format)
- **Code & Markdown Viewing**: Display source code and markdown documentation for each analysis node
- **Execution Status Tracking**: View execution states (not_executed, pending_validation, validated)
- **Metadata Management**: System-managed metadata with automatic synchronization
- **Responsive Design**: Clean UI with ResizablePanel layout
- **Caching Strategy**: Smart project caching for optimal performance

## Current Status

### ‚úÖ Implemented

- **Backend**:
  - FastAPI server with CORS support
  - Project and node metadata management
  - Parquet/JSON file serving with pagination
  - Code and markdown cell retrieval
  - Metadata synchronization and validation
  - Image and visualization file streaming

- **Frontend**:
  - React 18 + TypeScript with Vite
  - XYFlow-based DAG visualization
  - Interactive node selection with dependency highlighting
  - Data table with pagination
  - Project switching with caching
  - Markdown viewer for node descriptions
  - Code viewer for execution code
  - Responsive sidebar navigation

- **Notebook Format**:
  - Hybrid metadata approach: Cell metadata as source of truth
  - System-managed metadata comments with clear "understand to edit" markers
  - Automatic synchronization between Cell metadata and code comments
  - Metadata consistency validation

- **Test Data**:
  - Two complete example projects with 5 validated nodes each
  - All result files in Parquet format for uniform data handling

### üîÑ Roadmap (TODO)

#### Phase 2: Code Editing & Persistence
- [ ] Implement code editing UI in frontend
- [ ] API endpoint for saving code changes: `POST /api/projects/{projectId}/nodes/{nodeId}/save`
- [ ] Save code modifications to `.ipynb` file
- [ ] Auto-sync code comments with Cell metadata on save
- [ ] Draft state management to prevent cache pollution
- [ ] Unsaved changes warning on project switch

#### Phase 3: Execution & Result Updates
- [ ] Implement Jupyter kernel execution backend
- [ ] Execution progress tracking and status updates
- [ ] API endpoint: `POST /api/projects/{projectId}/nodes/{nodeId}/execute`
- [ ] Cache invalidation and refresh after execution
- [ ] Execution result loading from parquet/JSON
- [ ] Execution history tracking

#### Future Enhancements
- [ ] Real-time collaboration (multi-user editing)
- [ ] Version control integration for notebook changes
- [ ] Advanced filtering and search for large projects
- [ ] Performance optimization for complex DAGs
- [ ] Additional result format support (CSV, Excel, etc.)

## Architecture

### Frontend
- **Framework**: React 18 + TypeScript
- **Build Tool**: Vite
- **UI Components**: Shadcn/ui + TailwindCSS
- **Flow Visualization**: XYFlow for DAG rendering
- **State Management**: React Hooks + Custom useProjectCache hook
- **Caching**: In-memory project cache with smart loading strategy

### Backend
- **Framework**: FastAPI + Uvicorn
- **Notebook Management**: NotebookManager for incremental .ipynb operations
- **Project Management**: ProjectManager for project lifecycle
- **Node Type System**: Standardized, extensible node type architecture (see Node Types System below)
- **Data Format**: Parquet (primary), JSON (legacy, being phased to parquet)
- **Data Processing**: Pandas for DataFrame operations

## Project Structure

```
jupyter_analysis_visualize/
‚îú‚îÄ‚îÄ frontend/                          # React application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FlowDiagram.tsx        # DAG visualization
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DataTable.tsx          # Result data display
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DataSourceSidebar.tsx  # Project selection
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AnalysisSidebar.tsx    # Node details panel
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Index.tsx              # Main page layout
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useProjectCache.ts     # Project caching logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.ts                 # API client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Hardcoded fallback data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.tsx
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.ts
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json
‚îÇ   ‚îî‚îÄ‚îÄ .env.local                     # Frontend API configuration
‚îÇ
‚îú‚îÄ‚îÄ backend/                           # Python backend
‚îÇ   ‚îú‚îÄ‚îÄ app.py                         # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ notebook_manager.py            # .ipynb file operations
‚îÇ   ‚îú‚îÄ‚îÄ project_manager.py             # Project management
‚îÇ   ‚îú‚îÄ‚îÄ metadata_parser.py             # Metadata extraction
‚îÇ   ‚îú‚îÄ‚îÄ execution_manager.py           # Node execution and result management
‚îÇ   ‚îú‚îÄ‚îÄ kernel_manager.py              # Jupyter kernel management
‚îÇ   ‚îú‚îÄ‚îÄ node_types/                    # Node type system (extensible)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                # Module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                    # BaseNode abstract class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ registry.py                # Node type registry and factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_source.py             # DataSourceNode implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ compute.py                 # ComputeNode implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chart.py                   # ChartNode implementation
‚îÇ   ‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_test_projects.py  # Test data generator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_node_system.py        # Node system unit tests
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_*.py                  # Other unit tests
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îÇ
‚îú‚îÄ‚îÄ projects/                          # Project data directory
‚îÇ   ‚îú‚îÄ‚îÄ test_user_behavior_analysis/   # Example project 1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project.ipynb              # Jupyter notebook
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project.json               # Project metadata
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parquets/                  # Result files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Node definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ visualizations/            # Chart images
‚îÇ   ‚îî‚îÄ‚îÄ test_sales_performance_report/ # Example project 2
‚îÇ       ‚îî‚îÄ‚îÄ [same structure]
‚îÇ
‚îú‚îÄ‚îÄ reports/                           # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ OPTIMIZATION_SUMMARY.md
‚îÇ   ‚îú‚îÄ‚îÄ NOTEBOOK_MANAGER_OPTIMIZATION.md
‚îÇ   ‚îú‚îÄ‚îÄ METADATA_STORAGE_EVALUATION.md
‚îÇ   ‚îú‚îÄ‚îÄ CACHING_STRATEGY.md
‚îÇ   ‚îî‚îÄ‚îÄ CHANGES.txt
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

## Quick Start

### Prerequisites
- Python 3.9+
- Node.js 16+
- Git

### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create and activate virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies using uv (faster) or pip
uv pip install -r requirements.txt
# OR: pip install -r requirements.txt

# Start FastAPI server
python -m uvicorn app:app --reload --host 0.0.0.0 --port 8000
# Server will run on http://localhost:8000
# API docs available at http://localhost:8000/docs
```

### Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Configure API endpoint (update if backend is on different address)
echo "VITE_API_BASE_URL=http://localhost:8000" > .env.local

# Start development server
npm run dev
# App will run on http://localhost:5173
```

### Verify Setup

1. Open http://localhost:5173 in your browser
2. You should see the flow diagram and two test projects:
   - **User Behavior Analysis**: 5 nodes showing data processing workflow
   - **Sales Performance Report**: 5 nodes showing sales analysis workflow
3. Click on any node to view its data, code, and markdown description

## API Endpoints

### Project Management
- `GET /api/projects` - List all available projects
- `GET /api/projects/{project_id}` - Get project metadata with DAG structure

### Node Data Access
- `GET /api/projects/{project_id}/nodes/{node_id}/data?page=1&page_size=10` - Get paginated node data (Parquet)
- `GET /api/projects/{project_id}/nodes/{node_id}/code` - Get node's execution code
- `GET /api/projects/{project_id}/nodes/{node_id}/markdown` - Get node's markdown description
- `GET /api/projects/{project_id}/nodes/{node_id}/image` - Stream image files
- `GET /api/projects/{project_id}/nodes/{node_id}/visualization` - Stream visualization files

### Health Check
- `GET /api/health` - Backend health status

## Data Storage Format

### Parquet Files
- **Format**: Apache Parquet (.parquet)
- **Usage**: DataFrame results from data processing nodes
- **Compression**: ~10:1 ratio
- **Benefits**: Columnar storage, efficient pagination, schema preservation
- **Location**: `projects/{project_id}/parquets/`

### JSON Files (Legacy)
- **Format**: JSON (.json)
- **Usage**: Statistics, metadata (being migrated to Parquet)
- **Location**: `projects/{project_id}/parquets/`

### Visualization Files
- **Format**: PNG images (.png)
- **Usage**: Chart and graph visualizations
- **Location**: `projects/{project_id}/visualizations/`

## Node Type System

The backend uses a standardized, extensible node type system for managing different types of analysis nodes. This ensures clear input/output specifications and automatic type inference.

### Core Node Types

Currently implemented:

#### 1. **DataSourceNode** (`type: "data_source"`)
- **Purpose**: Loads data from external sources (CSV, database, API, etc.)
- **Constraints**:
  - No dependencies (cannot depend on other nodes)
  - Must output a DataFrame
  - Can be depended on by any other node type
- **Output Type**: `dataframe`
- **Display Type**: `table`
- **Example**:
  ```python
  # @node_type: data_source
  # @node_id: sales_data
  sales_data = pd.read_csv('sales.csv')
  ```

#### 2. **ComputeNode** (`type: "compute"`)
- **Purpose**: Transforms and processes data
- **Constraints**:
  - Must have at least one dependency
  - Input must be DataFrames from other nodes
  - Must output a DataFrame (for chaining with other compute or visualization nodes)
  - Cannot output dict/list (use analysis nodes for statistical results)
- **Output Type**: `dataframe`
- **Display Type**: `table`
- **Example**:
  ```python
  # @node_type: compute
  # @node_id: processed_sales
  # @depends_on: [sales_data]
  processed_sales = sales_data.groupby('region').sum()
  ```

#### 3. **ChartNode** (`type: "chart"`)
- **Purpose**: Creates visualizations and interactive charts
- **Constraints**:
  - Can depend on any node type
  - Must output either Plotly Figure or ECharts configuration
  - Typically a leaf node (not depended on by other nodes)
- **Output Types**: `plotly` or `echarts`
- **Display Types**: `plotly_chart` or `echarts_chart`
- **Example**:
  ```python
  # @node_type: chart
  # @node_id: visualization
  # @depends_on: [processed_sales]
  import plotly.graph_objects as go
  fig = go.Figure(data=[go.Bar(x=processed_sales.index, y=processed_sales.values)])
  visualization = fig
  ```

### Architecture

The node type system is organized in `backend/node_types/`:

- **base.py**: `BaseNode` abstract class defining the interface
  - `validate_inputs()`: Validate input data matches node requirements
  - `infer_output()`: Infer output type from execution result
  - `NodeOutput`: Dataclass describing output (type and display)
  - `NodeMetadata`: Dataclass storing node information

- **registry.py**: `NodeTypeRegistry` and factory functions
  - `register_node_type`: Decorator to register custom node types
  - `get_node_type()`: Retrieve node class by type name
  - `NodeTypeRegistry.list_types()`: List all registered types
  - Auto-registration of built-in types on module import

- **{node_type}.py**: Concrete node implementations
  - Each file contains one node type class
  - Easy to add new node types by creating new files

### Extensibility

Adding new node types is straightforward:

```python
# backend/node_types/analysis.py
from .base import BaseNode, NodeMetadata, NodeOutput, OutputType, DisplayType

@register_node_type
class AnalysisNode(BaseNode):
    """Analysis node for statistical computations"""
    node_type = "analysis"

    def __init__(self, metadata: NodeMetadata):
        if metadata.node_type != "analysis":
            raise ValueError(f"Expected analysis node")
        super().__init__(metadata)

    def validate_inputs(self, input_data):
        # Custom input validation
        return True

    def infer_output(self, result):
        # Infer output type from result
        if isinstance(result, dict):
            return NodeOutput(
                output_type=OutputType.DICT_LIST,
                display_type=DisplayType.JSON_VIEWER,
                description="Statistical results"
            )
        raise TypeError("Analysis must output dict or scalar")
```

The new node type is automatically registered and available throughout the system.

### Testing

Node system tests are in `backend/test/test_node_system.py`:

```bash
cd backend
uv run python test/test_node_system.py
```

Tests cover:
- Node type registration and discovery
- Node instantiation and validation
- Output type inference
- ExecutionManager integration

## Metadata Management

### System-Managed Metadata
The system uses a hybrid metadata approach:

```python
# Cell metadata (JSON, in .ipynb file)
{
  "node_type": "data_source",
  "node_id": "load_user_data",
  "execution_status": "validated",
  "depends_on": ["other_node_id"],
  "name": "Load User Data"
}

# Code comments (auto-generated, reflects Cell metadata)
# ===== System-managed metadata (auto-generated, understand to edit) =====
# @node_type: data_source
# @node_id: load_user_data
# @execution_status: validated
# @depends_on: [other_node_id]
# @name: Load User Data
# ===== End of system-managed metadata =====
```

### Key Principles
- **Cell metadata is the source of truth**: Always store primary metadata in Cell metadata
- **Code comments are for visibility**: Auto-generated from Cell metadata, users can see at a glance
- **Automatic synchronization**: System keeps comments synced with metadata
- **Safe for editing**: Code is editable without breaking metadata management

## Development Guide

### Adding Test Data

Generate new test projects:
```bash
cd backend
uv run python test/generate_test_projects.py
```

This creates two example projects with realistic data and analysis workflows.

### Understanding the Caching Strategy

The frontend implements smart project caching:

1. **First load**: Fetch project from backend, store in cache
2. **Project switch**: Check cache first, use cached data if available
3. **Editing phase** (future): Maintain Draft state separately from cache
4. **Save operation** (future): Update cache after successful save
5. **Execution** (future): Update cache with new execution results

See `frontend/CACHING_STRATEGY.md` for detailed design documentation.

### Metadata Validation

Validate metadata consistency in notebooks:
```bash
cd backend
uv run python -c "
from notebook_manager import NotebookManager
manager = NotebookManager('path/to/project.ipynb')
result = manager.validate_metadata_consistency()
print(f'Valid: {result[\"valid\"]}')
"
```

### Code Examples

#### Load and inspect a project
```python
from project_manager import ProjectManager

pm = ProjectManager('projects', 'test_user_behavior_analysis')
pm.load()

# View all nodes
for node in pm.metadata.nodes.values():
    print(f"{node['node_id']}: {node['name']}")
    print(f"  Type: {node['type']}")
    print(f"  Dependencies: {node['depends_on']}")
```

#### Validate metadata
```python
from notebook_manager import NotebookManager

manager = NotebookManager('projects/test_user_behavior_analysis/project.ipynb')
result = manager.validate_metadata_consistency()

if result['valid']:
    print("‚úÖ All metadata is consistent")
else:
    print("‚ùå Metadata inconsistencies found:")
    for error in result['errors']:
        print(f"  - {error}")
```

## Configuration

### Frontend Configuration
Create `frontend/.env.local`:
```
VITE_API_BASE_URL=http://localhost:8000
```

### Backend Configuration
Create `backend/.env` (copy from `.env.example`):
```
API_HOST=0.0.0.0
API_PORT=8000
```

## Troubleshooting

### Frontend can't connect to backend
1. Verify backend is running: `curl http://localhost:8000/api/health`
2. Check `VITE_API_BASE_URL` in `frontend/.env.local`
3. Check CORS configuration in `backend/app.py`

### Projects not showing up
1. Verify `projects/` directory exists with test projects
2. Check project structure: `projects/test_*/project.json` should exist
3. Run test data generator: `uv run python test/generate_test_projects.py`

### Port already in use
- **Backend**: Change API_PORT in `.env` or use different port in uvicorn command
- **Frontend**: `npm run dev -- --port 3001`

### Parquet file errors
1. Ensure pandas and pyarrow are installed: `uv pip install pandas pyarrow`
2. Verify file integrity: `python -c "import pandas as pd; pd.read_parquet('file.parquet')"`

## Technologies Used

### Frontend Stack
- **React 18**: UI framework
- **TypeScript**: Type safety
- **Vite**: Build tool and dev server
- **TailwindCSS**: Styling
- **shadcn/ui**: Component library
- **XYFlow**: DAG visualization library
- **Recharts**: Chart rendering

### Backend Stack
- **FastAPI**: Web framework
- **Uvicorn**: ASGI server
- **Pandas**: Data processing
- **PyArrow**: Parquet support
- **Python 3.9+**: Runtime

## Contributing

### Code Style
- Frontend: ESLint + Prettier configuration
- Backend: Follow PEP 8 standards
- Commit messages should be descriptive

### Testing
```bash
# Backend tests
cd backend
uv run pytest test/

# Frontend tests (planned)
cd frontend
npm run test
```

## Documentation

- [Metadata Storage Evaluation](reports/METADATA_STORAGE_EVALUATION.md) - Design decision documentation
- [Caching Strategy](frontend/CACHING_STRATEGY.md) - Frontend caching architecture
- [Optimization Summary](reports/OPTIMIZATION_SUMMARY.md) - Project optimization details
- [Changes Log](reports/CHANGES.txt) - Detailed change history

## License

MIT

## Contact

For questions or issues, please open a GitHub issue.
